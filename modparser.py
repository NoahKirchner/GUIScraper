import bs4 as bs
import lxml


# Class that you use to construct the modular parser (for lack of a better name).
class Parser:

    # Takes in the list generated by the scraper with the format of [(URL, content)]
    # and saves that internally.
    def __init__(self, inputlist:list):
        self.inputlist = inputlist

    # This is the function that displays the list of elements/class information
    # so that the person using the program can pick out an element to trim down to.
    # It takes in an integer that's used to exclude children out to a certain depth,
    # so for example when exclude is 4 you will only get the first 4 levels of tags
    # with their children omitted. It also requires that the internal list has at least
    # one piece of content saved.
    def normalize(self, exclude:int):
        selection = self.inputlist[0][1]
        selection = bs.BeautifulSoup(selection, 'lxml')
        selectionlist = []
        for tag in selection.findAll(True):
            if tag is not None:
                spaces = len(tag.findParents())
                if spaces <= exclude:
                    selectionlist.append((spaces * '+',tag.name, tag.attrs))
                elif exclude == 0:
                    selectionlist.append((spaces * '+', tag.name, tag.attrs))
                else:
                    pass
        return [item for item in selectionlist if item[1] not in ('script','link','form','button','img','input','style',
                                                                  'meta','noscript','select','iframe','nav','option', 'a')]
    # Returns a list of tuples. First item in the tuple is just for easier viewing,
    # the '+' is just equal to the level of depth of the child, so you can separate
    # parents from children on the printout. The second item is the element, and the third
    # is class information. The returned list also removes a bunch of junk that don't
    # have children, or if they do that wouldn't be worth scraping for whatever reason.
    # This does not remove them from the total output later necessarily, you just can't
    # select them as a parent element to trim by later.

    #Todo past me, I don't know what you were on when you wrote this, but it makes literally zero sense
    # this needs to take in the selection from above and to turn the content
    # from each into a beautifulsoup object with the selection args as the parse_only
    # flag. THEN add the url on and whatnot.

    # tbh future me just rewrite the whole thing
    def trim(self, selection: tuple):
        trimmedlist = []
        for item in self.inputlist:
            totrim = item[1].replace('\n', ' ').replace('\r', '')
            totrim = bs.BeautifulSoup(totrim, 'lxml')
            for match in totrim.findAll(selection[1:2]):
                if totrim is not None:
                    trimmedlist.append((item[1],match))
                    children = match.findChildren()
                    for child in children:
                        trimmedlist.append((item[1], child))
                else:
                    pass
        return trimmedlist

    def parse(self):
        return
